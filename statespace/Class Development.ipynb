{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5047527b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/NielsOta/Code/StateSpace/statespace')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "local_path = pathlib.Path().resolve()\n",
    "local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517f3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "from torch.autograd import Variable\n",
    "from scipy.optimize import minimize\n",
    "from collections import deque\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b7c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import _mm, _bmm, _inv, _mm3, _bmm3, _initiate_variables, _map_vector_to_matrices, _get_nan_positions, _remove_nan_tensor, _remove_inf_tensor, _get_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2747f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be forward method\n",
    "\n",
    "def _kalman_step(T, Z, R, Q, H, a, P, y):\n",
    "    \"\"\"\n",
    "    perform 1 step of the kalman filter\n",
    "    \"\"\"\n",
    "    \n",
    "    # prediction error: v\n",
    "    v = y - _mm(Z, a)\n",
    "    \n",
    "    # prediction error variance: F\n",
    "    F = _mm3(Z, P, Z.T) + H\n",
    "    \n",
    "    # incast-kalman gain: M\n",
    "    M = _mm3(P, Z.T, _inv(F)) \n",
    "    \n",
    "    # kalman gain: K\n",
    "    K = _mm(T, M)\n",
    "    \n",
    "    # incasted updates\n",
    "    att = a + _mm(M, v)\n",
    "    Ptt = P - _mm3(M, F, M.T)\n",
    "    \n",
    "    a_next = _mm(T, att)\n",
    "    P_next = _mm3(T, Ptt, T.T) + _mm3(R, Q, R.T)\n",
    "    \n",
    "    return a_next, P_next, att, Ptt, M, K, F, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c211c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be forward method\n",
    "\n",
    "def _kalman_step_missing(T, Z, R, Q, H, a, P, y, dtype=np.float64):\n",
    "    \"\"\"\n",
    "    perform 1 step of the kalman filter when observation is missing\n",
    "    \"\"\"\n",
    "    \n",
    "    # dimension of observation vector\n",
    "    s = int(y.shape[0])\n",
    "    \n",
    "    # prediction error: v\n",
    "    v = np.nan\n",
    "    \n",
    "    if s==1:\n",
    "        F = np.array([[np.inf]]).astype(dtype)\n",
    "    else:\n",
    "        # prediction error variance: F\n",
    "        F = np.eye(s).astype(dtype) * np.inf\n",
    "    \n",
    "    # incast-kalman gain: M\n",
    "    M = _mm3(P, Z.T, _inv(F).astype(dtype)) \n",
    "    \n",
    "    # kalman gain: K\n",
    "    K = np.zeros_like(_mm(T, M))\n",
    "    \n",
    "    # incasted updates\n",
    "    att = a\n",
    "    Ptt = P\n",
    "    \n",
    "    a_next = _mm(T, att)\n",
    "    P_next = _mm3(T, Ptt, T.T) + _mm3(R, Q, R.T)\n",
    "    \n",
    "    return a_next, P_next, att, Ptt, M, K, F, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d71f8419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_filter(*args):\n",
    "    \"\"\"\n",
    "    perform all the steps of the Kalman filter\n",
    "    \"\"\"\n",
    "    T, Z, R, Q, H, y, diffuse = args\n",
    "    \n",
    "    # number of observations\n",
    "    n = int(y.shape[2])\n",
    "    \n",
    "    # dimension of state vector\n",
    "    p = int(T.shape[0])\n",
    "    \n",
    "    # dimension of observation vector\n",
    "    s = int(y.shape[0])\n",
    "    \n",
    "    # initiate filters (a, att), filter variances (P, Ptt), errors (v), error variances (F), and Kalman gains (K, M)\n",
    "    a, att, P, Ptt, v, F, K, M = _initiate_variables(p, s, n)\n",
    "    \n",
    "    # get positions of missing observations\n",
    "    nan_pos_list = _get_nan_positions(y)\n",
    "    \n",
    "    # do a diffuse initialization\n",
    "    if diffuse:\n",
    "        a[:, :, 0] = 0\n",
    "        P[:, :, 0] = P[:, :, 0] + 1e5 * np.eye(p, p)\n",
    "\n",
    "    # iterate through time\n",
    "    for t in range(1, n):\n",
    "        \n",
    "        if t-1 not in nan_pos_list:\n",
    "            # a[0] contains a1, y[0] contains y1\n",
    "            y_t = y[:, :, t-1]\n",
    "            a[:, :, t], P[:, :, t], att[:, :, t-1], Ptt[:, :, t-1], M[:, :, t-1], K[:, :, t-1], F[:, :, t-1], v[:, :, t-1] = _kalman_step(T, Z, R, Q, H, a[:, :, t-1], P[:, :, t-1], y_t)\n",
    "        \n",
    "        else:\n",
    "            y_t = y[:, :, t-1]\n",
    "            a[:, :, t], P[:, :, t], att[:, :, t-1], Ptt[:, :, t-1], M[:, :, t-1], K[:, :, t-1], F[:, :, t-1], v[:, :, t-1] = _kalman_step_missing(T, Z, R, Q, H, a[:, :, t-1], P[:, :, t-1], y_t)\n",
    "    \n",
    "    if n-1 not in nan_pos_list:\n",
    "        # do final incasting update\n",
    "        y_t = y[:, :, n-1]\n",
    "        _, _, att[:, :, n-1], Ptt[:, :, n-1], M[:, :, n-1], K[:, :, n-1], F[:, :, n-1], v[:, :, n-1] = _kalman_step(T, Z, R, Q, H, a[:, :, n-1], P[:, :, n-1], y_t)\n",
    "    \n",
    "    else:\n",
    "        # do final incasting update\n",
    "        y_t = y[:, :, n-1]\n",
    "        _, _, att[:, :, n-1], Ptt[:, :, n-1], M[:, :, n-1], K[:, :, n-1], F[:, :, n-1], v[:, :, n-1] = _kalman_step_missing(T, Z, R, Q, H, a[:, :, n-1], P[:, :, n-1], y_t)\n",
    "    \n",
    "    return a, att, P, Ptt, F, v, K, M \n",
    "\n",
    "\n",
    "def kalman_forecast(*args, time=10, dtype=np.float64):\n",
    "    \"\"\"\n",
    "    forecast \n",
    "    \"\"\"\n",
    "    T, Z, R, Q, H, att, Ptt = args\n",
    "    \n",
    "    # number of observations\n",
    "    n = int(att.shape[2])\n",
    "    \n",
    "    # dimension of state vector\n",
    "    p = int(T.shape[0])\n",
    "    \n",
    "    # dimension of observation vector\n",
    "    s = int(att.shape[0])\n",
    "    \n",
    "    # initiate filters (a, att), filter variances (P, Ptt), errors (v), error variances (F), and Kalman gains (K, M)\n",
    "    a_forecast, P_forecast = np.zeros((p, 1, time + 1)).astype(dtype), np.zeros((p, p, n)).astype(dtype)\n",
    "    a_forecast[:,:,0], P_forecast[:,:,0] = att[:, :, -1], Ptt[:, :, -1]\n",
    "    \n",
    "    for t in range(1, time + 1):\n",
    "        a_forecast[:,:,t] = _mm(T, a_forecast[:,:,t-1])\n",
    "        P_forecast[:,:,t] = _mm3(T, P_forecast[:,:,t-1], T.T) + _mm3(R, Q, R.T)\n",
    "    \n",
    "    return a_forecast[:,:,1:], P_forecast[:,:,1:]\n",
    "\n",
    "\n",
    "def kalman_smoother(*args, dtype=np.float64):\n",
    "    \"\"\"\n",
    "    perform Kalman smoothing\n",
    "    \"\"\"\n",
    "    T, Z, R, Q, H, a, P, v, F, K = args\n",
    "    \n",
    "    # number of observations\n",
    "    n = int(a.shape[2])\n",
    "    \n",
    "    # dimension of state vector\n",
    "    p = int(T.shape[0])\n",
    "    \n",
    "    # dimension of observation vector\n",
    "    s = int(Z.shape[0])\n",
    "    \n",
    "    # instantiate a_hat\n",
    "    a_hat = np.zeros_like(a)\n",
    "    \n",
    "    # can einsum this operation because it does not iterate through time\n",
    "    T = np.repeat(T[:, :, None], n, axis=2)\n",
    "    \n",
    "    # L' = (T - KZ)'\n",
    "    L = T - np.einsum('ijn,jk->ikn', K, Z)\n",
    "    \n",
    "    # r[n+1] = r_n = 0\n",
    "    r = np.zeros((p, 1, n + 1)).astype(dtype)\n",
    "    \n",
    "    # a[0] contains a_1, y[0] contains y_1\n",
    "    \n",
    "    # from 99...0\n",
    "    for t in range(n-1, -1, -1):\n",
    "        \n",
    "        if np.isnan(v[:, :, t]):\n",
    "             r[:, :, t] =  r[:, :, t+1]\n",
    "        else:\n",
    "            r[:, :, t] = _mm3(Z.T, _inv(F[:, :, t]), v[:, :, t]) + _mm(L[:, :, t].T, r[:, :, t+1])\n",
    "    \n",
    "        a_hat[:, :, t] = a[:, :, t] + _mm(P[:, :, t], r[:, :, t])\n",
    "        \n",
    "    return a_hat, r, L, T\n",
    "\n",
    "\n",
    "def log_likelihood(params, *args):\n",
    "    \n",
    "    T, Z, R, Q, H, y, param_map, diffuse = args\n",
    "    T, Z, R, Q, H = _map_vector_to_matrices(params, param_map, T, Z, R, Q, H)\n",
    "    \n",
    "    # get means and variances\n",
    "    _, _, _, _, F, v, _, _  = kalman_filter(T, Z, R, Q, H, y, diffuse)\n",
    "    \n",
    "    if diffuse:\n",
    "        num_states = T.shape[0]\n",
    "        F = F[:, :, num_states:]\n",
    "        v = v[:, :, num_states:]\n",
    "    \n",
    "    # If an observation at time t is not present, should not include in log-likelihood\n",
    "    v = _remove_nan_tensor(v)\n",
    "    F = _remove_inf_tensor(F)\n",
    "    \n",
    "    # number of observations\n",
    "    n = int(y.shape[2])\n",
    "    \n",
    "    # dimension of state vector\n",
    "    p = int(T.shape[0])\n",
    "\n",
    "    # dimension of observation vector\n",
    "    s = int(y.shape[0])\n",
    "    \n",
    "    # get elementwise log determinants log|F|: check docs numpy returns (signs, abs of logdet)\n",
    "    F_logdets = np.linalg.slogdet(F.transpose(2, 0, 1))\n",
    "    F_logdets = F_logdets[0] * F_logdets[1]\n",
    "    \n",
    "    # get elementwise v'F^(-1)v, then convert shape from [100, 1, 1] -> [100]\n",
    "    vFv = np.squeeze(_bmm3(v.transpose(2, 1, 0), _inv(F.transpose(2, 0, 1)), v.transpose(2, 0, 1)))\n",
    "    \n",
    "    # constant value \n",
    "    const = s * np.log(2 * np.pi) * np.ones_like(vFv)\n",
    "    \n",
    "    # compute log-likelihood\n",
    "    llik = -(1/2) * np.sum(const + vFv + F_logdets) \n",
    "    \n",
    "    negative_llik = -llik.item()\n",
    "    \n",
    "    return negative_llik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b333bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26ef65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LinearGaussianModel:\n",
    "    \n",
    "    \"\"\"\n",
    "    class implementing a linear Gaussian model in StateSpace form\n",
    "    \n",
    "        y_t         = Z_t * alpha_t + epsilon_t              epsilon_t ~ N(0, H_t)\n",
    "        alpha_{t+1} = T_t * alpha_t + R_t * eta_t            eta_t ~ N(0, Q_t)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Declare observation vector\n",
    "    y: np.ndarray\n",
    "    \n",
    "    # Declare State Matrices \n",
    "    T: np.ndarray\n",
    "    Z: np.ndarray\n",
    "    R: np.ndarray\n",
    "    Q: np.ndarray\n",
    "    H: np.ndarray\n",
    "        \n",
    "    # Declare whether init is diffuse\n",
    "    diffuse: bool\n",
    "    \n",
    "    # Declare map for mapping param vector of optimizer to state matrices; e.g. 0: {\"matrix\" : \"Q\", \"index\": (0, 0, 0), \"constant\": True, \"bounds\": (None, None)}\n",
    "    param_map: Dict[int, Dict]\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        \n",
    "        # Get p, s, n: dimension state, dimension observation and length of y (time)\n",
    "        self.p = self.T.shape[0]\n",
    "        self.s = self.y.shape[0]\n",
    "        self.n = self.y.shape[2]\n",
    "        \n",
    "        # Get filtered and incasted signals and signal variances, \n",
    "        self.a, self.att, self.P, self.Ptt, self.v, self.F, self.K, self.M = _initiate_variables(self.p, self.s, self.n)\n",
    "        \n",
    "    def fit(self):\n",
    "        \n",
    "        # Get State Matrices \n",
    "        T = self.T\n",
    "        Z = self.Z\n",
    "        R = self.R\n",
    "        Q = self.Q\n",
    "        H = self.H\n",
    "\n",
    "        # Get whether init is diffuse\n",
    "        diffuse = self.diffuse\n",
    "\n",
    "        # Get map for mapping param vector of optimizer to state matrices\n",
    "        param_map= self.param_map\n",
    "\n",
    "        # Get observation vector\n",
    "        y = self.y\n",
    "        \n",
    "        # set options for minimization\n",
    "        options = {\n",
    "            'eps': 1e-7,\n",
    "            'disp': True,\n",
    "            'maxiter': 500\n",
    "        }\n",
    "        \n",
    "        # Get bounds for optimization\n",
    "        bounds = _get_bounds(param_map)\n",
    "        \n",
    "        params_ini = np.ones((len(param_map), 1))\n",
    "        \n",
    "        # maximize log-likelihook\n",
    "        res = minimize(log_likelihood, params_ini, args=(T, Z, R, Q, H, y, param_map, diffuse), method='L-BFGS-B', options=options, bounds=bounds)\n",
    "        \n",
    "        # extract params\n",
    "        params = res.x\n",
    "        print(params)\n",
    "        \n",
    "        # Update instance state matrices\n",
    "        T, Z, R, Q, H = _map_vector_to_matrices(params, param_map, T, Z, R, Q, H)\n",
    "        self.T, self.Z, self.R, self.Q, self.H = T, Z, R, Q, H\n",
    "        \n",
    "        # Get filtered and incasted signals and signal variances, \n",
    "        a, att, P, Ptt, v, F, K, M = kalman_filter(T, Z, R, Q, H, y, diffuse)\n",
    "        self.a, self.att, self.P, self.Ptt, self.v, self.F, self.K, self.M = a, att, P, Ptt, v, F, K, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36030d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_target_from_path(path: pathlib.Path, dtype=np.float64) -> torch.Tensor:\n",
    "    \n",
    "    if not path.exists():\n",
    "        return f\"path: {path} does not exist\"\n",
    "    \n",
    "    # read data\n",
    "    data = pd.read_csv(path).values\n",
    "    \n",
    "    # if array of shape (n,)\n",
    "    if data.ndim == 1:\n",
    "        data = data[:, np.newaxis]\n",
    "    \n",
    "    n = data.shape[0]\n",
    "    p = data.shape[1]\n",
    "    \n",
    "    y = data.T\n",
    "    y = y[:, None, :]\n",
    "  \n",
    "    return y.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ffbccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1616.27809536 14663.97320479]\n"
     ]
    }
   ],
   "source": [
    "dtype=np.float64\n",
    "base_dir = pathlib.Path().resolve().parent\n",
    "data_dir = base_dir / 'data'\n",
    "nile_path = data_dir / 'Nile.txt'\n",
    "\n",
    "# get data into shape [s, 1, n]\n",
    "y = read_target_from_path(nile_path, dtype)\n",
    "#y[:, :, 20:40] = np.nan\n",
    "\n",
    "# Declare State Matrices Local Level Model -> use [[]] for extra dimension\n",
    "T = np.array([[1]]).astype(dtype)\n",
    "Z = np.array([[1]]).astype(dtype)\n",
    "R = np.array([[1]]).astype(dtype)\n",
    "Q = np.array([[1]]).astype(dtype)\n",
    "H = np.array([[1]]).astype(dtype)\n",
    "diffuse = True\n",
    "\n",
    "dict_param_llm = {\n",
    "    0: {\"matrix\" : \"Q\", \"index\": (0, 0, 0), \"constant\": True, \"bounds\": (0.1, None)},\n",
    "    1:  {\"matrix\" : \"H\", \"index\": (0, 0, 0), \"constant\": True, \"bounds\": (0.1, None)}\n",
    "}\n",
    "\n",
    "llm = LinearGaussianModel(y, T, Z, R, Q, H, diffuse, dict_param_llm)\n",
    "llm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3ab12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
